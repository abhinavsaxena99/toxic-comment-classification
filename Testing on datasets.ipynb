{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import re \n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "from tensorflow import keras\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, LSTM, Bidirectional, Dropout, GlobalMaxPool1D, SpatialDropout1D, Conv1D, MaxPooling1D\n",
    "from keras.initializers import Constant\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam, SGD\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem.lancaster import LancasterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "embedding_dim = 300\n",
    "GLOVE_DIR = \"C:\\\\Users\\\\Abhinav\\\\Desktop\\\\Project Final\"\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.300d.txt'), encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22287, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1 = pd.read_csv('toxic.csv')\n",
    "train1 = pd.concat([train1[5000:16227],train1[16227+5000:]],axis=0)\n",
    "train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35000, 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('dataset.csv')\n",
    "train0 = train[train['toxic'] == 0][0:35000]\n",
    "# train0 = train[train['toxic'] == 0]\n",
    "# train0 = train0.sample(n=32287)\n",
    "train0.shape\n",
    "# 64574"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train0 = pd.read_csv('nontoxic.csv')\n",
    "# train0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29795</th>\n",
       "      <td>I can't find any source in English that says m...</td>\n",
       "      <td>0</td>\n",
       "      <td>4f17b9997721d774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>and asking top stop involving me</td>\n",
       "      <td>0</td>\n",
       "      <td>081166fea250a5af</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18313</th>\n",
       "      <td>Pic of the day Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>305b3ee7e7771b7d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26032</th>\n",
       "      <td>OK, Sarfatti called me worried about it. Is th...</td>\n",
       "      <td>0</td>\n",
       "      <td>44f0dc4275bae7f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35557</th>\n",
       "      <td>@ and @ What you say to it?</td>\n",
       "      <td>0</td>\n",
       "      <td>5f0301f2ee850b98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            comment_text  toxic  \\\n",
       "29795  I can't find any source in English that says m...      0   \n",
       "2996                    and asking top stop involving me      0   \n",
       "18313                           Pic of the day Wednesday      0   \n",
       "26032  OK, Sarfatti called me worried about it. Is th...      0   \n",
       "35557                        @ and @ What you say to it?      0   \n",
       "\n",
       "                     id  \n",
       "29795  4f17b9997721d774  \n",
       "2996   081166fea250a5af  \n",
       "18313  305b3ee7e7771b7d  \n",
       "26032  44f0dc4275bae7f1  \n",
       "35557  5f0301f2ee850b98  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.concat([train1,train0],axis=0)\n",
    "train = train.sample(frac=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57287, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text = str(text)\n",
    "    text = re.sub(\"[^a-zA-Z ]+\", \"\", text)\n",
    "    text = text.lower()\n",
    "    text_p = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    words = word_tokenize(text_p)\n",
    "    stop_words = stopwords.words('english')\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in filtered_words]   \n",
    "    return stemmed\n",
    "\n",
    "#     return filtered_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train['comment_text']\n",
    "# X_test = test['comment_text']\n",
    "y_train = train['toxic'].values\n",
    "# y_test = test['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.map(preprocess)\n",
    "# X_test = X_test.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "sequences = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_train = tokenizer.word_index \n",
    "vocab_train = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_index_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix_train = np.zeros((len(word_index_train) + 1, embedding_dim))\n",
    "for word, i in word_index_train.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix_train[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(len(word_index_train) + 1,\n",
    "                            embedding_dim,\n",
    "                            weights=[embedding_matrix_train],\n",
    "                            input_length=max_length,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "# model.add(Bidirectional(LSTM(60, return_sequences = True)))\n",
    "model.add(GRU(60, return_sequences = True))\n",
    "model.add(SpatialDropout1D(0.1))\n",
    "model.add(GlobalMaxPool1D())\n",
    "# model.add(Dropout(0.1))\n",
    "model.add(Dense(50,activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=64, epochs=6, validation_split=0.2, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('labeled_data.csv')\n",
    "\n",
    "# test = pd.read_csv('dataset.csv')\n",
    "# test = test[test['toxic'] == 0][84268:84268+10000]\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test['tweet']\n",
    "# X_test = test['comment_text']\n",
    "y_test = test['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 15s 40ms/step - loss: 0.3796 - accuracy: 0.8317\n",
      "test loss, test acc: [0.37957093119621277, 0.8317394852638245]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(X_test, y_test, batch_size=64)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "388/388 [==============================] - 15s 39ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred = model.predict(X_test, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.51      0.51      4163\n",
      "           1       0.90      0.90      0.90     20620\n",
      "\n",
      "    accuracy                           0.83     24783\n",
      "   macro avg       0.70      0.70      0.70     24783\n",
      "weighted avg       0.83      0.83      0.83     24783\n",
      "\n",
      "0.8325647066421723\n"
     ]
    }
   ],
   "source": [
    "tx_indices = y_pred>=0.5\n",
    "ntx_indices = y_pred<0.5\n",
    "y_pred[tx_indices] = 1\n",
    "y_pred[ntx_indices] = 0\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f1_score(y_test,y_pred,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2130  2033]\n",
      " [ 2137 18483]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "[tn, fp], [fn, tp] = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-toxic correctly recognised: 2130\n"
     ]
    }
   ],
   "source": [
    "print('Non-toxic correctly recognised:',tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic correctly recognised: 18483\n"
     ]
    }
   ],
   "source": [
    "print('Toxic correctly recognised:',tp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toxic misclassified as Non-toxic: 2137\n"
     ]
    }
   ],
   "source": [
    "print('Toxic misclassified as Non-toxic:',fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Toxic misclassified as Toxic: 2033\n"
     ]
    }
   ],
   "source": [
    "print('Non-Toxic misclassified as Toxic:',fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2t = pd.read_csv('toxic.csv')\n",
    "test2t = test2t[:5000]\n",
    "test2t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 3)"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2n = pd.read_csv('dataset.csv')\n",
    "# train0 = train[train['toxic'] == 0][0:64574]\n",
    "test2nt = test2n[test2n['toxic'] == 0][30000:30000+15000]\n",
    "test2nt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Hey... what is it..\\r\\n@ | talk .\\r\\nWhat is i...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bye! \\r\\n\\r\\nDon't look, come or think of comm...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are gay or antisemmitian? \\r\\n\\r\\nArchange...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        comment_text  toxic   id\n",
       "0       COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK      1  NaN\n",
       "1  Hey... what is it..\\r\\n@ | talk .\\r\\nWhat is i...      1  NaN\n",
       "2  Bye! \\r\\n\\r\\nDon't look, come or think of comm...      1  NaN\n",
       "3  You are gay or antisemmitian? \\r\\n\\r\\nArchange...      1  NaN\n",
       "4           FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!      1  NaN"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test2 = pd.concat([test2t,test2nt],axis=0)\n",
    "test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test2 = pd.read_csv('gab.csv')\n",
    "# test2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = test2['comment_text']\n",
    "y_test2 = test2['toxic'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test2 = X_test2.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(X_test2)\n",
    "X_test2 = pad_sequences(sequences, maxlen=max_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 41ms/step - loss: 0.2579 - accuracy: 0.8965\n",
      "test loss, test acc: [0.2578614354133606, 0.8964999914169312]\n"
     ]
    }
   ],
   "source": [
    "results2 = model.evaluate(X_test2, y_test2, batch_size=64)\n",
    "print(\"test loss, test acc:\", results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 13s 41ms/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "y_pred2 = model.predict(X_test2, batch_size=64, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.93     15000\n",
      "           1       0.75      0.87      0.81      5000\n",
      "\n",
      "    accuracy                           0.90     20000\n",
      "   macro avg       0.85      0.89      0.87     20000\n",
      "weighted avg       0.90      0.90      0.90     20000\n",
      "\n",
      "0.8988893186312785\n"
     ]
    }
   ],
   "source": [
    "tx_indices2 = y_pred2>=0.5\n",
    "ntx_indices2 = y_pred2<0.5\n",
    "y_pred2[tx_indices2] = 1\n",
    "y_pred2[ntx_indices2] = 0\n",
    "\n",
    "print(classification_report(y_test2, y_pred2))\n",
    "print(f1_score(y_test2,y_pred2,average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
